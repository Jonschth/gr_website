{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef925c1d",
   "metadata": {},
   "source": [
    "# Golden redfish in Icelandic waters: a statistical approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc1850c",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains the python code for the Golden redfish model that Maris Optimum has developed.\n",
    "Sources:\n",
    "    Data from Icelandic Marine and freshwater institute (1)\n",
    "    It uses the gradient boosting regression algorithm xgboost (2) and various packages (2)\n",
    "    It is written in the python programming language\n",
    "    \n",
    "    The main pacckages used are:\n",
    "    1.the xgboost regressor (https://xgboost.readthedocs.io/en/stable/index.html) \n",
    "    2.the scikit-learn suite (https://scikit-learn.org/stable/user_guide.html)\n",
    "    3.the shap suite (https://shap.readthedocs.io/en/latest/index.html) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c97f8",
   "metadata": {},
   "source": [
    "### Packages imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728a9b07",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "# import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import explained_variance_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f43d8",
   "metadata": {},
   "source": [
    "### Conversion of kg catch to unit of fish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b81530",
   "metadata": {},
   "source": [
    "The annual catch of the fleet is reported by weight. The statistical model is based on number of fish at each length cm. This conversion algorithm was developed to use data from the IMFI surveys to convert the catch into lengths and number of fish. To convert the IMFI annual data from kg to lengths polynomial regression was employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c694a369",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def catch_converter(X_catch_per_df, catch_df):\n",
    "    \"\"\"\n",
    "    Catch information used to formulate units from kg.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_catch_per_df : Dataframe containing percentages of catch\n",
    "    catch_df : Dataframe containing total cath in kg\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    catch_df : Dataframe containing total catch in lengths\n",
    "    \"\"\"\n",
    "    path_grs_str = 'R:/Ráðgjöf/Maris Optimum/Golden_redfish_model/'\n",
    "    wl_df = pd.read_csv(path_grs_str+'RED_gadget_n_at_age.csv', sep=',')\n",
    "\n",
    "    Xl = wl_df[['year', 'mean_length']].copy()\n",
    "    yl = wl_df[['year', 'mean_weight']].copy()\n",
    "\n",
    "    for index, row in Xl.iterrows():\n",
    "        Xl.at[index, 'squared'] = row[1]**2\n",
    "\n",
    "    for year in range(1985, 2022):\n",
    "        average_weight = 0\n",
    "        reg_X = Xl[Xl['year'] == year]\n",
    "        reg_y = yl[yl['year'] == year]\n",
    "        reg = LinearRegression().fit(\n",
    "            reg_X[['mean_length', 'squared']], reg_y[['mean_weight']])\n",
    "        b = reg.coef_[0][0]\n",
    "        a = reg.coef_[0][1]\n",
    "        c = reg.intercept_\n",
    "        for col in range(1010, 1060):\n",
    "            average_weight += (X_catch_per_df.loc[year, str(col)]) * (\n",
    "                a*(col - 1000)**2 + b*(col - 1000) + c)\n",
    "        catch_df.at[\n",
    "            year - 1985, 'number'] = catch_df.loc[\n",
    "                year - 1985, 'catch']/average_weight\n",
    "    return catch_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3121831e",
   "metadata": {},
   "source": [
    "### Data fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e267f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data(fractile):\n",
    "    \"\"\"\n",
    "    Fetch all data for the regression and prepare X and y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fractile : integer\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    XX_df : Dataframe with data for all dependent variables\n",
    "    YY : Dataframe with data for the independant variable\n",
    "\n",
    "    \"\"\"\n",
    "    path_str = 'R:\\\\Ráðgjöf\\\\Bláa hagkerfið\\\\Hafró\\\\distribution_output\\\\'\n",
    "    path_str_do = 'R:\\\\Ráðgjöf\\\\Maris Optimum/distribution_output\\\\'\n",
    "    X_df = pd.read_csv(path_str_do + 'distribution' + fractile + '.csv',\n",
    "                       sep=\",\")\n",
    "\n",
    "    ysq_df = X_df[['ar', 'max(cum)']]\n",
    "    ysq_df.set_index(['ar'], inplace=True)\n",
    "    ysq_df = ysq_df[~ysq_df.index.duplicated(keep='first')]\n",
    "\n",
    "    catch_df = pd.read_csv(path_str + 'golden_redfish_catch.csv',\n",
    "                           sep=\";\")\n",
    "\n",
    "    catch_df.at[37, 'year'] = 2022.0\n",
    "    catch_df.at[37, 'catch'] = 26\n",
    "    catch_df.at[37, 'number'] = 29\n",
    "\n",
    "    X_cal_df = pd.read_csv(path_str_do+'distribution_commercial.csv',\n",
    "                           sep=\",\")\n",
    "    X_cal_df.drop(1605, axis=0, inplace=True)\n",
    "\n",
    "    X_cal_df = X_cal_df.pivot(index='ar',\n",
    "                              columns='lengd',\n",
    "                              values='per_length')\n",
    "    X_cal_df = X_cal_df.fillna(0)\n",
    "    X_cal_df.columns = 1000 + X_cal_df.columns\n",
    "    X_cal_df.columns = X_cal_df.columns.astype(int).astype(str)\n",
    "\n",
    "    catch_df = catch_converter(X_cal_df, catch_df)\n",
    "    catch_df.year = catch_df.year.astype(int)\n",
    "    catch_df.set_index(catch_df.year, inplace=True)\n",
    "\n",
    "    X_cal_df = X_cal_df.mul(catch_df.number*-1e6, axis=0)\n",
    "\n",
    "    XX_df = X_df.pivot(index='ar',\n",
    "                       columns='lengd',\n",
    "                       values='per_length')\n",
    "\n",
    "    XX_df = pd.merge(XX_df, ysq_df, right_index=True, left_index=True)\n",
    "\n",
    "    # XX_df.drop(4.5, axis=1, inplace=True)\n",
    "    # XX_df.drop(6.4, axis=1, inplace=True)\n",
    "    XX_df.drop(11.9, axis=1, inplace=True)\n",
    "    XX_df.drop(12.5, axis=1, inplace=True)\n",
    "    XX_df.drop(12.6, axis=1, inplace=True)\n",
    "    XX_df.drop(13.1, axis=1, inplace=True)\n",
    "    XX_df.drop(13.4, axis=1, inplace=True)\n",
    "    XX_df.drop(13.6, axis=1, inplace=True)\n",
    "    XX_df.drop(13.7, axis=1, inplace=True)\n",
    "    XX_df.drop(13.9, axis=1, inplace=True)\n",
    "    XX_df.drop(14.4, axis=1, inplace=True)\n",
    "    XX_df.drop(14.5, axis=1, inplace=True)\n",
    "    XX_df.drop(14.7, axis=1, inplace=True)\n",
    "    XX_df.drop(14.8, axis=1, inplace=True)\n",
    "    XX_df.drop(14.9, axis=1, inplace=True)\n",
    "\n",
    "    XX_df.columns = XX_df.columns.astype(str)\n",
    "\n",
    "    YX = pd.read_csv(path_str+\"RED_numbers_at_age.csv\", sep=\";\")\n",
    "    YY = YX.iloc[15:53, 28]\n",
    "\n",
    "    XX_df = XX_df.join(X_cal_df.iloc[:, :])\n",
    "\n",
    "    XX_df.index = XX_df.index.astype(str)\n",
    "    \n",
    "    XX_df = XX_df.fillna(0)\n",
    "\n",
    "    return (XX_df, YY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e425029",
   "metadata": {},
   "source": [
    "### Plot over possible result range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1e97c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result_range(result_dict, interval_int, fractile, regressor_type):\n",
    "    \"\"\"\n",
    "    Plot mae and r^2 for the range of the looped regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_dict : a dictianary containing the results from different regression\n",
    "    over the interval.\n",
    "    interval_int : integer with the increments used over the interval\n",
    "    fractile : fractile used for Winsorization\n",
    "    regressor_type : TYPE\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    result_dict['x'] = range(343, 493, int(interval_int/1e6))\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.set(style='whitegrid',\n",
    "            palette='pastel', )\n",
    "    sns.lineplot(x='x',\n",
    "                 y='r2',\n",
    "                 data=result_dict,\n",
    "                 color=\"red\",\n",
    "                 ax=ax)\n",
    "    ax.set(xlabel='size of stock in millions',\n",
    "           ylabel='r2, red',\n",
    "           title='school fractile:'+fractile+'\\n' +\n",
    "           'regressor type :' + regressor_type + '\\n'+'1985-2022',\n",
    "           ylim=(0, 1))\n",
    "\n",
    "    ax2 = ax.twinx()\n",
    "    sns.lineplot(x='x',\n",
    "                 y='mae',\n",
    "                 data=result_dict,\n",
    "                 color='blue',\n",
    "                 markers=True, ax=ax2)\n",
    "    ax2.set(ylabel='mean average error, blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25a98d",
   "metadata": {},
   "source": [
    "### Shap calculations and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb88d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_calculations_xgb(regressor, XX_df):\n",
    "    \"\"\"\n",
    "    Calculate shap vales for the xgb_regressor and the dependant variables.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    regressor : TYPE\n",
    "        DESCRIPTION.\n",
    "    XX_df : TYPE\n",
    "        DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None.\n",
    "\n",
    "    \"\"\"\n",
    "    explainer = shap.TreeExplainer(regressor)\n",
    "\n",
    "    shap_values = explainer.shap_values(XX_df)\n",
    "\n",
    "    shap.summary_plot(shap_values,\n",
    "                      XX_df,\n",
    "                      plot_type=\"bar\",\n",
    "                      max_display=50)\n",
    "\n",
    "    shap_values = explainer(XX_df)\n",
    "    shap.waterfall_plot(shap_values[37], max_display=40)\n",
    "    shap.waterfall_plot(shap_values[35], max_display=40)\n",
    "    shap.waterfall_plot(shap_values[33], max_display=40)\n",
    "    shap.waterfall_plot(shap_values[31], max_display=40)\n",
    "    shap.waterfall_plot(shap_values[29], max_display=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e223d87",
   "metadata": {},
   "source": [
    "### Regression over possible ending values of stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bafd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_over_possible_values_XGB(X, y, interval_int, training_set_int):\n",
    "    \"\"\"\n",
    "    Loop over possible stock sizes, regressing in every step.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : Dataframe with dependant variables.\n",
    "    y : TDataframe with independant variables\n",
    "    interval_int : step interval.\n",
    "    training_set_int :\n",
    "        0 = random set,\n",
    "        1 = test data is 2015-2019,\n",
    "        2 = test data is 2015-2022\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result_dict : json string with solutions in each interval.\n",
    "\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'nthread': [0],\n",
    "        'eval_metric': [\"mae\"],\n",
    "        'learning_rate': [.2, .3],\n",
    "        'max_depth': [2, 3, 4],\n",
    "        'min_child_weight': [2],\n",
    "        'subsample': [0.5, 0.6],\n",
    "        'colsample_bytree': [.6, .7],\n",
    "        'n_estimators': [50]\n",
    "    }\n",
    "    test_size = .25\n",
    "    seed = 3\n",
    "    result_dict = {'fjoldi2022': [], 'fjoldi2021': [],\n",
    "                   'fjoldi2020': [], 'mae': [], 'rmse': [], 'r2': [],\n",
    "                   'evs': []}\n",
    "\n",
    "    xgb1 = xgb.XGBRegressor(objective='reg:squarederror', seed=seed)\n",
    "    X_initial = X\n",
    "    first_loop_bool = True\n",
    "    for add_int in range(0, 150000000, interval_int):\n",
    "\n",
    "        if training_set_int == 0:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X,\n",
    "                y,\n",
    "                test_size=test_size,\n",
    "                random_state=seed)\n",
    "\n",
    "        elif training_set_int == 1:\n",
    "            X_train = pd.concat([X.iloc[:27, :], X.iloc[35:38, :]])\n",
    "            y_train = pd.concat([y.iloc[:27], y.iloc[35:38]])\n",
    "            X_test = X.iloc[28:35, :]\n",
    "            y_test = y.iloc[28:35]\n",
    "\n",
    "        elif training_set_int == 2:\n",
    "            X_train = X.iloc[:27, :]\n",
    "            y_train = y.iloc[:27]\n",
    "            X_test = X.iloc[28:37, :]\n",
    "            y_test = y.iloc[28:37]\n",
    "\n",
    "        n_iter = 200\n",
    "        n_iter = n_iter\n",
    "\n",
    "        xgb_regressor = GridSearchCV(xgb1,\n",
    "                                     parameters,\n",
    "                                     cv=2,\n",
    "                                     verbose=0)\n",
    "\n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "\n",
    "        xgb_regressor.fit(X_train,\n",
    "                          y_train,\n",
    "                          eval_set=eval_set,\n",
    "                          verbose=False)\n",
    "\n",
    "        y_pred_test = xgb_regressor.predict(X_test)\n",
    "        if first_loop_bool:\n",
    "            print(xgb_regressor.predict(X_initial))\n",
    "            first_loop_bool = False\n",
    "\n",
    "        result_dict['fjoldi2022'].append(y[52])\n",
    "        result_dict['fjoldi2021'].append(y[51])\n",
    "        result_dict['fjoldi2020'].append(y[50])\n",
    "\n",
    "        result_dict['mae'].append(mean_absolute_error(y_test,\n",
    "                                                      y_pred_test))\n",
    "        result_dict['rmse'].append(math.sqrt(mean_squared_error(y_test,\n",
    "                                                                y_pred_test)))\n",
    "        result_dict['r2'].append(r2_score(y_test,\n",
    "                                          y_pred_test))\n",
    "        result_dict['evs'].append(explained_variance_score(y_test,\n",
    "                                                           y_pred_test))\n",
    "        y[50] += interval_int * (y[50]/y[51])\n",
    "        y[51] += interval_int * (y[51]/y[52])\n",
    "        y[52] += interval_int\n",
    "\n",
    "    min_value = min(result_dict['mae'])\n",
    "    min_index = result_dict['mae'].index(min_value)\n",
    "\n",
    "    y[50] = result_dict['fjoldi2020'][min_index]\n",
    "    y[51] = result_dict['fjoldi2021'][min_index]\n",
    "    y[52] = result_dict['fjoldi2022'][min_index]\n",
    "\n",
    "    regressor = GridSearchCV(xgb1,\n",
    "                             parameters,\n",
    "                             cv=2,\n",
    "                             verbose=0)\n",
    "    if training_set_int == 0:\n",
    "        regressor.fit(X, y)\n",
    "        params = regressor.best_params_\n",
    "        regressor = xgb.XGBRegressor(**params)\n",
    "        regressor.fit(X, y)\n",
    "        shap_calculations_xgb(regressor, X)\n",
    "\n",
    "    elif training_set_int == 1:\n",
    "        X_train = pd.concat([X.iloc[:27, :], X.iloc[35:38, :]])\n",
    "        y_train = pd.concat([y.iloc[:27], y.iloc[35:38]])\n",
    "        regressor.fit(X_train, y_train)\n",
    "        params = regressor.best_params_\n",
    "        regressor = xgb.XGBRegressor(**params)\n",
    "        regressor.fit(X_train, y_train)\n",
    "\n",
    "    elif training_set_int == 2:\n",
    "        X_train = X.iloc[:29, :]\n",
    "        y_train = y.iloc[:29]\n",
    "        regressor.fit(X_train, y_train)\n",
    "        params = regressor.best_params_\n",
    "        regressor = xgb.XGBRegressor(**params)\n",
    "        regressor.fit(X_train, y_train)\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57867a0",
   "metadata": {},
   "source": [
    "### Running code1: Using Random training sets, testing them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac1b34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.01754918e+09 9.95990784e+08 9.65723584e+08 8.87165824e+08\n",
      " 8.90765824e+08 7.05598592e+08 9.21117440e+08 8.64598848e+08\n",
      " 7.81613568e+08 7.27467456e+08 6.95072128e+08 9.12124160e+08\n",
      " 8.98976768e+08 9.26670784e+08 7.76759552e+08 7.48095744e+08\n",
      " 7.11625152e+08 7.09909248e+08 7.16985664e+08 7.81927040e+08\n",
      " 7.93865088e+08 8.42196288e+08 9.22171008e+08 8.85786816e+08\n",
      " 8.88552704e+08 9.70892928e+08 1.01823494e+09 9.77502976e+08\n",
      " 8.44777856e+08 7.82459776e+08 7.68444864e+08 7.67497408e+08\n",
      " 5.50266560e+08 5.99166464e+08 5.16962304e+08 4.78591040e+08\n",
      " 3.79948800e+08 5.26103008e+08]\n"
     ]
    }
   ],
   "source": [
    "fractile = '096'\n",
    "interval_int = 1000000\n",
    "training_set_int = 0\n",
    "\n",
    "(X, y) = get_new_data(fractile)\n",
    "\n",
    "result_dict_gb = regression_over_possible_values_XGB(X,\n",
    "                                                     y,\n",
    "                                                     interval_int,\n",
    "                                                     training_set_int)\n",
    "regressor_type = 'rgb'\n",
    "plot_result_range(result_dict_gb, interval_int, fractile, regressor_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e651174",
   "metadata": {},
   "source": [
    "### Running code2: Using fixed training sets, testing the period 1985-2014 and 2020-2022. \n",
    "training_set_int :\n",
    "\n",
    "        1 = test data is 2015-2019, training data 1985-2014 and 2020-2022. This enables the regressor to predict the values for y in the period 2015-2019 based on all other values. These predictions are then used in running code3 to adjust the y values and run a random training test again\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845175c2",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "fractile = '096'\n",
    "interval_int = 1000000\n",
    "training_set_int = 1\n",
    "\n",
    "(X, y) = get_new_data(fractile)\n",
    "\n",
    "result_dict_gb = regression_over_possible_values_XGB(X,\n",
    "                                                     y,\n",
    "                                                     interval_int,\n",
    "                                                     training_set_int)\n",
    "regressor_type = 'rgb'\n",
    "plot_result_range(result_dict_gb, interval_int, fractile, regressor_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10b8aa8",
   "metadata": {},
   "source": [
    "### Running code3: Using Random training sets, testing them. \n",
    "Using the results from running code2 the ys for the period 2015-2019 are adjusted in accordance with the prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91acede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fractile = '096'\n",
    "interval_int = 1000000\n",
    "training_set_int = 0\n",
    "\n",
    "(X, y) = get_new_data(fractile)\n",
    "\n",
    "\n",
    "y[42] -= 142000000\n",
    "y[43] -= 290000000\n",
    "y[44] -= 306000000\n",
    "y[45] -= 248000000\n",
    "y[46] -= 154000000\n",
    "y[47] -= 19000000\n",
    "y[48] -= 26000000\n",
    "y[49] += 52000000\n",
    "y[50] += 7000000\n",
    "\n",
    "result_dict_gb = regression_over_possible_values_XGB(X,\n",
    "                                                     y,\n",
    "                                                     interval_int,\n",
    "                                                     training_set_int)\n",
    "regressor_type = 'rgb'\n",
    "plot_result_range(result_dict_gb, interval_int, fractile, regressor_type)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
